{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Libraries & Environment Setup </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Environment management\n",
    "import numpy as np  # Numpy\n",
    "import random  # Determinism\n",
    "import torch  # PyTorch\n",
    "import torch.nn as nn  # Neural network module\n",
    "import torch.optim as optim  # Optimizers\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import matplotlib.animation as animation # Animation\n",
    "import warnings  # Silence some sklearn warnings\n",
    "import optuna # Hyperparameter optimization\n",
    "\n",
    "from collections import Counter  # Counting\n",
    "from torchvision import datasets, transforms  # Datasets and transformations\n",
    "from sklearn.cluster import KMeans  # KMeans clustering algorithm\n",
    "from sklearn.model_selection import train_test_split  # Train-test split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  # Confusion matrix\n",
    "from sklearn.manifold import TSNE  # t-SNE\n",
    "from tqdm.notebook import tqdm  # Progress bars\n",
    "\n",
    "from models import CNN  # Neural network class\n",
    "from trainers import KMeansConsistencyTrainer  # Training function\n",
    "from datasets import get_mnist_loaders, split_dataset  # Dataset functions\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")    # Silence some annoying sklearn warnings\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Due to sklearn bug\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seeds for determinism\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MNIST Data Preparation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "train_loader, test_loader = get_mnist_loaders(batch_size=128)\n",
    "\n",
    "# Split dataset into labeled and unlabeled subsets\n",
    "mnist_train = train_loader.dataset\n",
    "# labeled_data, unlabeled_data = split_dataset(mnist_train, num_labeled=250)\n",
    "\n",
    "# Create data loaders for labeled and unlabeled data\n",
    "# labeled_loader = torch.utils.data.DataLoader(labeled_data, batch_size=128, shuffle=True, num_workers=0)\n",
    "# unlabeled_loader = torch.utils.data.DataLoader(unlabeled_data, batch_size=128, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Training Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "def experiment(values_of_M, epochs=10, evaluate_every=1, lambda_kmeans=0.1, lambda_consistency=0.1, use_consistency=False, use_unlabeled=True, save_dir=\"tsne_images\", output_file=\"tsne_animation.gif\", generate_tsne=True, generate_cm=True):\n",
    "    results = {}\n",
    "    for M in values_of_M:\n",
    "        # Create model instance\n",
    "        model = CNN(use_dropout = True, dropout_rate = 0.3)\n",
    "        trainer = KMeansConsistencyTrainer(model, device=device)\n",
    "\n",
    "        # Split dataset\n",
    "        labeled_data, unlabeled_data = split_dataset(mnist_train, M)\n",
    "        # print_label_distribution(labeled_data, description=f\"Labeled Dataset for M={M}\")\n",
    "        \n",
    "        labeled_loader = torch.utils.data.DataLoader(labeled_data, batch_size=256, shuffle=True, num_workers=0)\n",
    "        unlabeled_loader = torch.utils.data.DataLoader(unlabeled_data, batch_size=256, shuffle=True, num_workers=0) if use_unlabeled else None\n",
    "\n",
    "        # Train and log results\n",
    "        train_accs, test_accs = trainer.train(\n",
    "            labeled_loader=labeled_loader, \n",
    "            unlabeled_loader=unlabeled_loader, \n",
    "            test_loader=test_loader, \n",
    "            epochs=epochs, \n",
    "            evaluate_every=evaluate_every\n",
    "        )\n",
    "        results[M] = (train_accs, test_accs)\n",
    "        # print(f\"Train accuracy for M={M}: {train_accs[-1]:.2f}%, Test accuracy for M={M}: {test_accs[-1]:.2f}%\")\n",
    "\n",
    "\n",
    "        # Evaluate and compute confusion matrix\n",
    "        test_accuracy, preds, labels = trainer.evaluate(test_loader)\n",
    "        if generate_cm:\n",
    "            cm = confusion_matrix(labels, preds)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "            disp.plot(cmap=\"viridis\")\n",
    "            plt.title(f\"Confusion Matrix for M={M}\")\n",
    "            plt.show()\n",
    "\n",
    "        if generate_tsne:\n",
    "            # Plot t-SNE visualization\n",
    "            plot_tsne(model, M, test_loader)\n",
    "\n",
    "    if generate_tsne:\n",
    "        create_animation(save_dir, output_file)\n",
    "    return results\n",
    "\n",
    "# Plot training curves\n",
    "def plot_training_curves(results, values_of_M):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot test accuracy for each M\n",
    "    for M in values_of_M:\n",
    "        train_accs, test_accs = results[M]\n",
    "        plt.plot(test_accs, label=f\"M={M} (Test Accuracy)\")\n",
    "\n",
    "    plt.title(\"Test Accuracy vs. Epochs for Different Values of M\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Test Accuracy (%)\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Plot t-SNE visualization\n",
    "def plot_tsne(model, M, data_loader, save_dir=\"tsne_images\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, features = model(images)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "            labels_list.append(labels.cpu().numpy())\n",
    "    features = np.concatenate(features_list)\n",
    "    labels = np.concatenate(labels_list)\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    tsne_results = tsne.fit_transform(features)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels, cmap='viridis', alpha=0.5)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(f't-SNE Visualization for M={M}')\n",
    "    plt.savefig(os.path.join(save_dir, f'tsne_M_{M}.png'))\n",
    "    plt.show()  # Display the plot in the output\n",
    "    plt.close()\n",
    "\n",
    "def create_animation(save_dir=\"tsne_images\", output_file=\"tsne_animation.gif\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    images = []\n",
    "    \n",
    "    # Extract numeric values of M from filenames and sort them\n",
    "    file_names = sorted(\n",
    "        [f for f in os.listdir(save_dir) if f.startswith('tsne_M_') and f.endswith('.png')],\n",
    "        key=lambda x: int(x.split('_')[2].split('.')[0])\n",
    "    )\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        img = plt.imread(os.path.join(save_dir, file_name))\n",
    "        images.append([plt.imshow(img, animated=True)])\n",
    "    \n",
    "    ani = animation.ArtistAnimation(fig, images, interval=500, blit=True, repeat_delay=1000)\n",
    "    ani.save(os.path.join(save_dir, output_file), writer='imagemagick')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Hyperparameter Optimization with Optuna </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    lambda_kmeans = trial.suggest_loguniform('lambda_kmeans', 1e-5, 1e-1)\n",
    "    lambda_consistency = trial.suggest_loguniform('lambda_consistency', 1e-6, 1e-2)\n",
    "    # dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
    "    \n",
    "    # Use a fixed value of M for the optimization\n",
    "    M = 100  # You can change this value as needed\n",
    "    values_of_M = [M]\n",
    "    \n",
    "    # Run the experiment with the current hyperparameters\n",
    "    results = experiment(\n",
    "        values_of_M=values_of_M, \n",
    "        epochs=10, \n",
    "        evaluate_every=2,\n",
    "        lambda_kmeans=lambda_kmeans, \n",
    "        lambda_consistency=lambda_consistency, \n",
    "        use_consistency=True, \n",
    "        use_unlabeled=True, \n",
    "        generate_tsne=False, \n",
    "        generate_cm=False\n",
    "    )\n",
    "    \n",
    "    # Get the test accuracy for the current hyperparameters\n",
    "    test_accs = results[M][1]\n",
    "    best_test_acc = max(test_accs)\n",
    "    \n",
    "    return best_test_acc\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "set_seed(7 * 5 * 3 * 2 * 2)\n",
    "\n",
    "study_name = \"Optimize_KMeans_and_Consistency_Losses\"\n",
    "study = optuna.create_study(study_name=study_name, direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize Hyperparameter Optimization Results </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization History Plot\n",
    "history_plot = optuna.visualization.plot_optimization_history(study)\n",
    "history_plot.show()\n",
    "\n",
    "# Hyperparameter Importance Plot\n",
    "importance_plot = optuna.visualization.plot_param_importances(study)\n",
    "importance_plot.show()\n",
    "\n",
    "# Parallel Coordinate Plot\n",
    "parallel_plot = optuna.visualization.plot_parallel_coordinate(study)\n",
    "parallel_plot.show()\n",
    "\n",
    "# Slice Plot\n",
    "slice_plot = optuna.visualization.plot_slice(study)\n",
    "slice_plot.show()\n",
    "\n",
    "# Contour Plot\n",
    "contour_plot = optuna.visualization.plot_contour(study)\n",
    "contour_plot.show()\n",
    "\n",
    "# EDF Plot\n",
    "edf_plot = optuna.visualization.plot_edf(study)\n",
    "edf_plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
